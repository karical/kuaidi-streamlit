# streamlit_app.py
import random

import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import time
from glob import glob

from PIL import Image

from backend import load_model, detect_video_frame, crop_express_image
from utils.clean import check_img_size

# é¡µé¢é…ç½®
st.set_page_config(layout="wide")
st.title("ğŸš€ å¿«é€’å•ç‰ˆé¢æ£€æµ‹æ¼”ç¤º")

# â€”â€” ä¾§è¾¹æ ï¼šæ¨¡å‹é€‰æ‹© & å‚æ•°è°ƒæ•´ â€”â€” #
st.sidebar.header("è®¾ç½®")

# é¢„è®¾æ¨¡å‹é€‰é¡¹
model_options = {
    "v1": "./models/kuaidi_20250224_v1_best.onnx",
    "v2": "./models/kuaidi_20250227_best.onnx",
    "v3": "./models/kuaidi_20250310_v3_best.onnx",
}
model_choice = st.sidebar.selectbox("é€‰æ‹© ONNX æ¨¡å‹", list(model_options.keys()))

if model_options[model_choice] is None:
    custom_path = st.sidebar.text_input("è‡ªå®šä¹‰ ONNX æ¨¡å‹è·¯å¾„", "")
    model_path = custom_path.strip() or None
else:
    model_path = model_options[model_choice]

# æ£€æµ‹å‚æ•°
conf_thres = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.5, 0.01)
iou_thres  = st.sidebar.slider("NMS IOU é˜ˆå€¼", 0.0, 1.0, 0.45, 0.01)
img_size   = st.sidebar.number_input("è¾“å…¥å°ºå¯¸ï¼ˆæ­£æ–¹å½¢ï¼‰", 64, 1280, 640, step=32)
max_det    = st.sidebar.number_input("æœ€å¤§æ£€æµ‹æ•°", 1, 10, 3, step=1)

# è§†é¢‘æºé€‰æ‹©ï¼šä¸Šä¼ æˆ–ç¤ºä¾‹
st.sidebar.header("é€‰æ‹©è§†é¢‘æ¥æº")
video_source = st.sidebar.radio("", ["ä¸Šä¼ è§†é¢‘", "ç¤ºä¾‹è§†é¢‘"])

if video_source == "ä¸Šä¼ è§†é¢‘":
    uploaded = st.file_uploader("ä¸Šä¼ è§†é¢‘æ–‡ä»¶", type=["mp4", "avi", "mov"])
    video_path = None
else:
    sample_dir = r"./resource/video"
    sample_files = glob(os.path.join(sample_dir, "*.*"))
    sample_names = [os.path.basename(f) for f in sample_files]
    sample_choice = st.sidebar.selectbox("é€‰æ‹©ç¤ºä¾‹è§†é¢‘", sample_names)
    video_path = os.path.join(sample_dir, sample_choice)
    uploaded = None

start_btn = st.sidebar.button("å¼€å§‹ç¦»çº¿æ£€æµ‹å¹¶æ’­æ”¾")

# Session State ç¼“å­˜
if "processed_frames" not in st.session_state:
    st.session_state.processed_frames = []
    st.session_state.frame_results   = []
    st.session_state.fps             = None

# ç¦»çº¿æ£€æµ‹é€»è¾‘
if start_btn:
    # é€‰æ‹©è§†é¢‘æº
    if video_source == "ä¸Šä¼ è§†é¢‘":
        if not uploaded:
            st.error("è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶")
            st.stop()
        t_in = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        t_in.write(uploaded.read())
        t_in.flush()
        t_in.close()
        cap = cv2.VideoCapture(t_in.name)
    else:
        cap = cv2.VideoCapture(video_path)

    # æ ¡éªŒæ¨¡å‹è·¯å¾„
    if not model_path:
        st.error("âš ï¸ è¯·é€‰æ‹©æˆ–è¾“å…¥æœ‰æ•ˆçš„æ¨¡å‹è·¯å¾„")
        cap.release()
        st.stop()

    # åŠ è½½æ¨¡å‹
    model = load_model(model_path)
    stride = 32

    fps   = cap.get(cv2.CAP_PROP_FPS) or 10
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0

    # é‡ç½®ç¼“å­˜
    st.session_state.fps = fps
    st.session_state.processed_frames.clear()
    st.session_state.frame_results.clear()

    progress_bar = st.sidebar.progress(0)
    status_text  = st.sidebar.empty()

    # æ‰¹é‡æ£€æµ‹
    for idx in range(total):
        ret, frame = cap.read()
        if not ret:
            break
        annotated, result = detect_video_frame(
            model, frame,
            img_size=check_img_size(img_size, s=stride),
            model_stride=stride,
            conf_thres=conf_thres,
            iou_thres=iou_thres,
            max_det=max_det
        )
        st.session_state.processed_frames.append(annotated)
        st.session_state.frame_results.append(result)

        progress_bar.progress((idx + 1) / total)
        status_text.text(f"å·²å¤„ç†å¸§ï¼š{idx+1}/{total}")

    cap.release()
    status_text.text("âœ… ç¦»çº¿æ£€æµ‹å®Œæˆï¼Œå¼€å§‹æ’­æ”¾")

    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆä¸Šä¼ æ¨¡å¼ï¼‰
    if video_source == "ä¸Šä¼ è§†é¢‘":
        try:
            os.unlink(t_in.name)
        except:
            pass


#æ’­æ”¾åŒº

if st.session_state.processed_frames:
    # 1. å…ˆåˆ›å»ºä¸€æ¬¡ä¸¤åˆ—å¸ƒå±€å’Œå ä½ç¬¦
    video_col, info_col = st.columns([4, 1])
    video_slot = video_col.empty()
    info_slot  = info_col.empty()

    display_width = 600

    # 2. ç„¶åå†å¾ªç¯æ’­æ”¾ï¼Œæ¯æ¬¡åªæ›´æ–°å ä½ç¬¦å†…å®¹
    for frame, result in zip(st.session_state.processed_frames, st.session_state.frame_results):
        # æ›´æ–°è§†é¢‘å¸§
        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        video_slot.image(img, width=display_width)

        # æ›´æ–°å³ä¾§ä¿¡æ¯ï¼šæŠŠæ‰€æœ‰ç›®æ ‡ä¿¡æ¯åˆæˆä¸€æ®µ HTML/Markdownï¼Œä¸€æ¬¡æ€§æ›´æ–°
        if result:
            md = ""
            for o in result:
                x1, y1, x2, y2 = o["position"]
                md += f"""
<div style="background-color:#f8f9fa;border:1px solid #dee2e6;border-radius:4px;padding:8px;margin-bottom:8px;">
  <div style="font-size:35px;font-weight:bold;color:#343a40;">ç±»åˆ«</div>
  <div style="font-size:30px;font-weight:bold;color:#113a40;text-align: center;">{o['label']}</div>
  <div style="font-size:35px;color:#155724;">ç½®ä¿¡åº¦:</div>
  <div style="font-size:35px;color:#155724;text-align: center;">{o['conf']:.2f}</div>
  <div style="font-size:30px;color:#856404;">åæ ‡:</div>
  <div style="font-size:30px;color:#856404;text-align: center;">({x1}, {y1}), ({x2}, {y2})</div>
</div>
"""
            info_slot.markdown(md, unsafe_allow_html=True)
        else:
            info_slot.markdown(
                '<div style="background-color:#f8d7da;padding:8px;border-radius:4px;">'
                '<span style="font-size:16px;color:#721c24;">æœ¬å¸§æœªæ£€æµ‹åˆ°ç›®æ ‡</span>'
                '</div>',
                unsafe_allow_html=True
            )

        # cropped = crop_express_image(frame, result)
        # # è½¬æˆ RGB å¹¶å±•ç¤º
        # cropped_rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)
        # info_col.image(cropped_rgb, caption="è£å‰ªåçš„å¿«é€’å•åŒºåŸŸ", use_container_width=True)

        # æ§åˆ¶å¸§ç‡ï¼Œè®©æ›´æ–°çœ‹èµ·æ¥è¿è´¯
        time.sleep(1.0 / st.session_state.fps)

    # æ’­æ”¾ç»“æŸæç¤º
    st.toast("æ£€æµ‹å·²å®Œæˆï¼", icon="âœ…")

#########################
all_crops = []
for frame, results in zip(st.session_state.processed_frames, st.session_state.frame_results):
    for det in results:
        # æ‹¿æœ€é«˜ç½®ä¿¡åº¦çš„â€œvalid areaâ€åšè£å‰ª
        if det["label"] == "valid area":
            crop = crop_express_image(frame, [det])
            all_crops.append((crop, det["conf"]))
# æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå–å‰ä¸‰
top30 = sorted(all_crops, key=lambda x: x[1], reverse=True)[:30]
n = min(3, len(top30))
if n > 0:
    top3 = random.sample(top30, n)
else:
    top3 = []
# åœ¨æ’­æ”¾åŒºä¸‹æ–¹ï¼Œå±•ç¤ºä¸‰å¼ è£å‰ªå›¾
top3_paths = []
if top3:
    st.markdown("### ğŸ“¦ ç½®ä¿¡åº¦æœ€é«˜çš„ä¸‰å¼ è£å‰ªç»“æœ")
    cols = st.columns(3)
    for (img_crop, conf), col in zip(top3, cols):
        # BGRâ†’RGB
        img_rgb = cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB)
        col.image(img_rgb, use_container_width=True)
        col.caption(f"ç½®ä¿¡åº¦: {conf:.2f}")

        # ä¿å­˜å›¾ç‰‡ä¸ºä¸´æ—¶æ–‡ä»¶
        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
        img_pil = Image.fromarray(img_rgb)
        img_pil.save(tmp_file.name)
        top3_paths.append(tmp_file.name)

# ä¿å­˜åˆ° session_state
st.session_state.top3_image_paths = top3_paths
#########################
